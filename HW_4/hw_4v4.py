# -*- coding: utf-8 -*-
"""HW_4v4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZvHYU-Ul4qOVh4oPDu_ALBS2Pvt4MS8Z
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.preprocessing import LabelEncoder, StandardScaler

try:
      file_path = 'Titanic-Dataset.csv'
      df_tit = pd.read_csv(file_path)
      print(f"Файл {file_path} загружен")

except Exception as e: # Catching a more general exception
      print(f"Ошибка загрузки файла: {e}")

df_tit.head(10)

#Набор Titanic-Dataset.csv from https://www.kaggle.com/datasets/yasserh/titanic-dataset
#Определяем выжил или нет
#Survived: выжил или нет: 0 = нет, 1 = да
#Pclass: класс билета: 1, 2, 3
#Name: Имя
#Sex: пол
#Age: возраст
#SibSp: количество братьев и сестер / супругов на борту «Титаника»
#Parch: количество родителей/детей на борту «Титаника»
#Ticket: номер билета
#Fare: cтоимость проезда
#Cabin: номер каюты
#Embarked: порт посадки: C = Шербур, Q = Куинстаун, S = Саутгемптон

df_tit.info()

print(df_tit["Survived"].value_counts())

# насколько я понимаю, в классе "Выжившие" намного меньше записей, из за-чего в расчете модели класс "Погибшие" будет иметь больший вес

# Выжило каждого пола 0 = нет, 1 = да
sns.countplot(x="Sex", hue="Survived", data=df_tit)
plt.title("Выжило каждого пола")
plt.show()

# Выжило в разрезе класса кают 0 = нет, 1 = да
sns.countplot(x="Pclass", hue="Survived", data=df_tit)
plt.title("Выжило в разрезе класса кают")
plt.show()

# График по возрастам
plt.figure(figsize=(8,5))
sns.histplot(df_tit["Age"].dropna(), kde=True, bins=30)
plt.title("Возраст")
plt.show()

#Пустые значения
print(df_tit.isnull().sum())

#Может и неправильно, но решил удалить некоторые столбцы
# PassengerId, Name, Ticket - не несут смысловой нагрузки по моему мнению
# Cabin - возможно было бы интересно, но почти все пустые
df_tit.drop(['PassengerId','Name','Ticket','Cabin'], axis=1, inplace=True)

df_tit['Sex'] = df_tit['Sex'].map({'male':0, 'female':1}) # в числа
df_tit.fillna({'Age':df_tit['Age'].median()}, inplace = True) # пропуски заполним медианным значением
df_tit['Embarked'].fillna(df_tit['Embarked'].mode()[0], inplace=True) # пропуски заполним наиболее часто встречающимся значением

# Encode categorical features
le = LabelEncoder()
for col in ['Embarked']:
    data[col] = le.fit_transform(data[col])

# Encode categorical features
le = LabelEncoder()
for col in ['Embarked']:
    df_tit[col] = le.fit_transform(df_tit[col])

df_tit.head()

#Посмтрим теперь корреляцию
import matplotlib.pyplot as plt
import seaborn as sns

corr=df_tit.corr()

plt.figure(figsize=(8,6))
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f")
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler

X = df_tit.drop(columns=['Survived'])
y = df_tit['Survived']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("Тренировка:", X_train_scaled.shape)
print("Тест:",X_test_scaled.shape)

!pip install -q catboost xgboost lightgbm

from catboost import CatBoostClassifier
from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier, RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score


#список моделей для сравнения
models = {
     "CatBoost": CatBoostClassifier (iterations=500, learning_rate=0.05, depth=6, verbose=False),
     "AdaBoost": AdaBoostClassifier(n_estimators=250, random_state=42),
     "GradientBoosting": GradientBoostingClassifier(random_state=42),
     "DecisionTree": DecisionTreeClassifier(random_state=42),
     "KNeighbors": KNeighborsClassifier(n_neighbors=11)
}

results = {}
for name, model in models.items():
    model.fit(X_train_scaled, y_train)
    y_pred  = model.predict(X_test_scaled)
    results[name] = accuracy_score(y_test, y_pred )

print("Model Accuracies:")
for k,v in results.items():
    print(f"{k}: {v:.4f}")

best_model_name = max(results, key=results.get)
best_model = models[best_model_name]

print("\nBest Model:", best_model_name)

print("\nClassification Report (Best Model):\n", classification_report(y_test, best_model.predict(X_test_scaled)))

print("Confusion Matrix (Best model):\n", confusion_matrix(y_test, best_model.predict(X_test_scaled)))

importances = best_model.feature_importances_
feature_names = X.columns
feat_imp = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
feat_imp = feat_imp.sort_values(by='Importance', ascending=False)
# Plot
plt.figure(figsize=(10,6))
sns.barplot(x='Importance', y='Feature', data=feat_imp)
plt.title('Feature Importance - Best Model')
plt.xlabel('Importance Score')
plt.ylabel('Feature')
plt.show()
print(feat_imp)

print(df_tit["Survived"].value_counts())
#Выживших намного меньше чем погибших, попробуем сбалансировать классы и выполнить модели

#------OVERSAMPLING---------:
#количество выживших увеличим до количества погибших
#Простое повторное использование данных заключается в увеличении числа экземпляров класса-меньшинства
#путем случайного повторного выбора данных из этого класса до достижения желаемой пропорции между классами
from imblearn.over_sampling import RandomOverSampler

print("Размерность базовая X_train_scaled:", X_train_scaled.shape)
print("Размерность базовая y_train:", y_train.shape)

print("Разбивка базовая по классам:", y_train.value_counts())

ros = RandomOverSampler(random_state=42)
X_train_over, y_train_over = ros.fit_resample(X_train_scaled, y_train)
print("Новая размерность X_train_over:", X_train_over.shape)
print("Новая размерность y_train_over:", y_train_over.shape)
print("Разбивка новая по классам:", y_train_over.value_counts())

#По обоим классам теперь 444 - по значению большего класса

results_over = {}
for name, model in models.items():
    model.fit(X_train_over, y_train_over)
    y_pred  = model.predict(X_test_scaled)
    results_over[name] = accuracy_score(y_test, y_pred )

print("Model Accuracies:")
for k,v in results_over.items():
    print(f"{k}: {v:.4f}")

best_model_over_name = max(results_over, key=results_over.get)
best_model_over = models[best_model_over_name]

print("\nBest Model:", best_model_over_name)

#Без Oversampling/ Undersampling
#Model Accuracies:
#CatBoost: 0.8212
#AdaBoost: 0.8101
#GradientBoosting: 0.8101
#DecisionTree: 0.7821
#KNeighbors: 0.7989

#Best Model: CatBoost

print("\nClassification Report (Best Model):\n", classification_report(y_test, best_model_over.predict(X_test_scaled)))

#Без Oversampling/ Undersampling
#Classification Report:
#               precision    recall  f1-score   support
#
#           0       0.83      0.87      0.85       105
#           1       0.80      0.76      0.78        74
#
#    accuracy                           0.82       179
#   macro avg       0.82      0.81      0.81       179
#weighted avg       0.82      0.82      0.82       179

print("Confusion Matrix (Best Model):\n", confusion_matrix(y_test, best_model_over.predict(X_test_scaled)))
 #Без Oversampling/ Undersampling
 #[[91 14]
 #[18 56]]

importances = best_model_over.feature_importances_
feature_names = X.columns
feat_imp = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
feat_imp = feat_imp.sort_values(by='Importance', ascending=False)
# Plot
plt.figure(figsize=(10,6))
sns.barplot(x='Importance', y='Feature', data=feat_imp)
plt.title('Feature Importance - Best Model')
plt.xlabel('Importance Score')
plt.ylabel('Feature')
plt.show()
print(feat_imp)
#Без Oversampling/ Undersampling
#    Feature  Importance
#1       Sex   27.936431
#5      Fare   23.921499
#2       Age   23.229213
#0    Pclass   11.582579
#3     SibSp    5.155063
#6  Embarked    4.383122
#4     Parch    3.792092

#------UNDERSAMPLING---------:
#количество погибших уменьшим до количества выживших
#Процесс заключается в случайном удалении части примеров из большего класса до достижения желаемого баланса.
from imblearn.under_sampling import RandomUnderSampler

print("Размерность базовая X_train_scaled:", X_train_scaled.shape)
print("Размерность базовая y_train:", y_train.shape)

print("Разбивка базовая по классам:", y_train.value_counts())

ros = RandomUnderSampler(random_state=42)
X_train_under, y_train_under = ros.fit_resample(X_train_scaled, y_train)
print("Новая размерность X_train_under:", X_train_under.shape)
print("Новая размерность y_train_under:", y_train_under.shape)
print("Разбивка новая по классам:", y_train_under.value_counts())

#По обоим классам теперь 268 - по значению меньшего класса

results_under = {}
for name, model in models.items():
    model.fit(X_train_under, y_train_under)
    y_pred  = model.predict(X_test_scaled)
    results_under[name] = accuracy_score(y_test, y_pred )

print("Model Accuracies:")
for k,v in results_under.items():
    print(f"{k}: {v:.4f}")

best_model_under_name = max(results_under, key=results_under.get)
best_model_under = models[best_model_under_name]

print("\nBest Model:", best_model_under_name)

#Без Oversampling/ Undersampling
#Model Accuracies:
#CatBoost: 0.8212
#AdaBoost: 0.8101
#GradientBoosting: 0.8101
#DecisionTree: 0.7821
#KNeighbors: 0.7989

#Best Model: CatBoost

print("\nClassification Report (Best Model):\n", classification_report(y_test, best_model_under.predict(X_test_scaled)))

#Без Oversampling/ Undersampling
#Classification Report:
#               precision    recall  f1-score   support
#
#           0       0.83      0.87      0.85       105
#           1       0.80      0.76      0.78        74
#
#    accuracy                           0.82       179
#   macro avg       0.82      0.81      0.81       179
#weighted avg       0.82      0.82      0.82       179

print("Confusion Matrix (Best Model):\n", confusion_matrix(y_test, best_model_under.predict(X_test_scaled)))
 #Без Oversampling/ Undersampling
 #[[91 14]
 #[18 56]]

importances = best_model_under.feature_importances_
feature_names = X.columns
feat_imp = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
feat_imp = feat_imp.sort_values(by='Importance', ascending=False)
# Plot
plt.figure(figsize=(10,6))
sns.barplot(x='Importance', y='Feature', data=feat_imp)
plt.title('Feature Importance - Best Model')
plt.xlabel('Importance Score')
plt.ylabel('Feature')
plt.show()
print(feat_imp)
#Без Oversampling/ Undersampling
#    Feature  Importance
#1       Sex   27.936431
#5      Fare   23.921499
#2       Age   23.229213
#0    Pclass   11.582579
#3     SibSp    5.155063
#6  Embarked    4.383122
#4     Parch    3.792092

#По классу выживших матрица стала немного лучше в обоих случаях (OVER и UDER),
#но в UNDER точность моделей немного понизилась,
#в OVER вес пола (Sex) сильно увеличился и поменялась лучшая модель
#Думаю, что на этот dataset оба способа балансировки классов оказывают небольшое влияние