# -*- coding: utf-8 -*-
"""HW_5v1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v9tYTUS4yJXQBt8-hC-DzyXHqT01clS5
"""

import pandas as pd

try:
      file_path = 'uber.csv'
      df_uber = pd.read_csv(file_path)
      print(f"Файл {file_path} загружен")

except Exception as e: # Catching a more general exception
      print(f"Ошибка загрузки файла: {e}")

df_uber.head(10)

#Набор Uber Fares Dataset from https://www.kaggle.com/datasets/yasserh/uber-fares-dataset
#Предсказываем стоимость поездки - fare_amount
#Unnamed: 0	: индекс
#key: уникальный идентификатор поездки
#fare_amount: стоимость поездки в USD
#pickup_datetime: дата и время включения счетчика
#pickup_longitude: долгота где был включен счетчик
#pickup_latitude: широта где был включен счетчик
#dropoff_longitude: долгота где был отключен счетчик
#dropoff_latitude	: широта где был отключен счетчик
#passenger_count: количество пассажиров

print(df_uber.info())

df_uber.describe()

print(df_uber.isnull().sum())

print('Минимальная долгота начала поездки:',df_uber['pickup_longitude'].min())
print('Максимальная долгота начала поездки:',df_uber['pickup_longitude'].max())
print('Минимальная долгота окончания поездки:',df_uber['dropoff_longitude'].min())
print('Максимальная долгота окончания поездки:',df_uber['dropoff_longitude'].max())

print('Минимальная широта начала поездки:',df_uber['pickup_latitude'].min())
print('Максимальная широта начала поездки:',df_uber['pickup_latitude'].max())
print('Минимальная широта окончания поездки:',df_uber['dropoff_latitude'].min())
print('Максимальная широта окончания поездки:',df_uber['dropoff_latitude'].max())

print('Минимальная оплата:',df_uber['fare_amount'].min())
print('Максимальная оплата:',df_uber['fare_amount'].max())
print('Минимальная количество пассажиров:',df_uber['passenger_count'].min())
print('Максимальное количество пассажиров:',df_uber['passenger_count'].max())

#Чистим данные

#Удалим все строки, где есть null
df_uber.dropna(inplace=True)

print(df_uber.isnull().sum())

#Теперь удалим нереальные долготу и широту
def in_world(v_lat, v_lon):
    return (-90 <= v_lat <= 90) and (-180 <= v_lon <= 180)

df_uber = df_uber[df_uber.apply(lambda row: in_world(row['pickup_latitude'], row['pickup_longitude'])
                                        and in_world(row['dropoff_latitude'], row['dropoff_longitude']), axis=1)]

print('Минимальная долгота начала поездки:',df_uber['pickup_longitude'].min())
print('Максимальная долгота начала поездки:',df_uber['pickup_longitude'].max())
print('Минимальная долгота окончания поездки:',df_uber['dropoff_longitude'].min())
print('Максимальная долгота окончания поездки:',df_uber['dropoff_longitude'].max())

print('Минимальная широта начала поездки:',df_uber['pickup_latitude'].min())
print('Максимальная широта начала поездки:',df_uber['pickup_latitude'].max())
print('Минимальная широта окончания поездки:',df_uber['dropoff_latitude'].min())
print('Максимальная широта окончания поездки:',df_uber['dropoff_latitude'].max())

# Удалим неправильную оплату
df_uber = df_uber[df_uber['fare_amount'] > 0]

# Удалим неправильное количество пассажиров:
# Максимальное количество пассажиров в Uber зависит от тарифа: для UberX это 4 человека, а для тарифов UberXL, Uber Black SUV и UberXXL — до 6 человек.
df_uber = df_uber[(df_uber['passenger_count'] > 0) & (df_uber['passenger_count'] < 7)]

print('Минимальная оплата:',df_uber['fare_amount'].min())
print('Максимальная оплата:',df_uber['fare_amount'].max())
print('Минимальная количество пассажиров:',df_uber['passenger_count'].min())
print('Максимальное количество пассажиров:',df_uber['passenger_count'].max())

print(df_uber.info())

#Большая часть значений долготы и широты: -73 широта	41 долгота.	Это примерно Нью-Йорк (40°43′42″ с. ш. 73°59′39″ з. д. из Википедии )
#Ограничим выборку этим регионом
def in_NY(v_lat, v_lon):
    return (40 <= v_lat <= 42) and (-75 <= v_lon <= -72)

df_uber = df_uber[df_uber.apply(lambda row: in_NY(row['pickup_latitude'], row['pickup_longitude'])
                                        and in_NY(row['dropoff_latitude'], row['dropoff_longitude']), axis=1)]

print('Минимальная долгота начала поездки:',df_uber['pickup_longitude'].min())
print('Максимальная долгота начала поездки:',df_uber['pickup_longitude'].max())
print('Минимальная долгота окончания поездки:',df_uber['dropoff_longitude'].min())
print('Максимальная долгота окончания поездки:',df_uber['dropoff_longitude'].max())

print('Минимальная широта начала поездки:',df_uber['pickup_latitude'].min())
print('Максимальная широта начала поездки:',df_uber['pickup_latitude'].max())
print('Минимальная широта окончания поездки:',df_uber['dropoff_latitude'].min())
print('Максимальная широта окончания поездки:',df_uber['dropoff_latitude'].max())

#Проверим и сконвертируем дата и время включения счетчика
df_uber['pickup_datetime'] = pd.to_datetime(df_uber['pickup_datetime'], errors='coerce')

#что бы не возиться со форматом времени, создадим новые поля на его основе
df_uber['hour'] = df_uber['pickup_datetime'].dt.hour
df_uber['day'] = df_uber['pickup_datetime'].dt.day
df_uber['month'] = df_uber['pickup_datetime'].dt.month
df_uber['year'] = df_uber['pickup_datetime'].dt.year
df_uber['weekday'] = df_uber['pickup_datetime'].dt.weekday

#Превратим координаты в растояние: Формула гаверсинуса позволяет рассчитать расстояние между двумя точками на поверхности сферы, используя их широту и долготу
from math import radians, sin, cos, sqrt, atan2

#Евклидово
def distance_GS(p_lat1, p_lon1, p_lat2, p_lon2):
    R_Earth = 6371  # Earth radius in km

    p_lat1, p_lon1, p_lat2, p_lon2 = map(radians, [p_lat1, p_lon1, p_lat2, p_lon2])
    dlat, dlon = p_lat2 - p_lat1, p_lon2 - p_lon1

    a = sin(dlat/2)**2 + cos(p_lat1)*cos(p_lat2)*sin(dlon/2)**2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))
    return R_Earth * c

#Манхэттен
def distance_mh(p_lat1, p_lon1, p_lat2, p_lon2):
    dis_x = distance_GS(p_lat1, p_lon1, p_lat1, p_lon2)
    dis_y = distance_GS(p_lat1, p_lon1, p_lat2, p_lon1)
    return dis_x+dis_y

df_uber['distance'] = df_uber.apply(lambda row: distance_mh(
    row['pickup_latitude'], row['pickup_longitude'],
    row['dropoff_latitude'], row['dropoff_longitude']), axis=1)

df_uber = df_uber[df_uber["distance"] > 0]

df_uber.head(10)

#Визуализация
import seaborn as sns
import matplotlib.pyplot as plt
sns.scatterplot(x=df_uber['distance'], y=df_uber['fare_amount'])
plt.title("Стоимость и Расстояние (км)")
plt.show()

#Ящик с усами (интересно как получилось 140 км наездить)
sns.boxplot(x=df_uber['fare_amount'])
plt.title("Выбросы")
plt.show()

#Матрица корреляции
corr_matrix = df_uber[['fare_amount', 'passenger_count', 'distance', 'hour', 'day', 'month', 'weekday']].corr()

sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title("Матрица корреляции")
plt.show()

#Поскольку надо было отработать с make_classification, то сгенерируем с его помощью поле "Оценка поездки" - grade
from sklearn.datasets import make_classification

p_rows = len(df_uber) # Количество создаваемых строк
p_feat = 6            # Количество признаков
p_grade = 5         # Оценки от 0 до  4)

X_grade, y_grade = make_classification(
    n_samples=p_rows,
    n_features=p_feat,
    n_informative=3, # информативные
    n_redundant=0,
    n_classes=p_grade,
    n_clusters_per_class=1,
    random_state=42
)

# Добавляем сгенерированный столбец

print('Старый размер данных: ',df_uber.shape)

# Создаем новую колонку
df_uber['grade'] = y_grade

print('Новый размер данных: ',df_uber.shape)

#Контрольная проверка данных
print('\nПустые: \n')
print(df_uber.isnull().sum())
print('\nОписание: \n')
print(df_uber.info())
print('\nДанные: \n')
print(df_uber.head(10))
print('\nРазмер датасета: ',len(df_uber))

#Начинаем работу с моделями
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

features = ["passenger_count", "distance", "hour", "day", "month", "year", "weekday",
            "pickup_latitude", "pickup_longitude", "dropoff_latitude", "dropoff_longitude"]

X = df_uber[features] #признаки
y = df_uber["fare_amount"] #цель

# делаим на тренировочную и тетсовую
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Стандартизация - все признаки числовые
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

import matplotlib.pyplot as plt

def result_visual(y_test, y_pred):
    plt.figure(figsize=(6, 6))
    plt.scatter(y_test, y_pred, alpha=0.6)
    plt.plot(
       [y_test.min(), y_test.max()],
       [y_test.min(), y_test.max()],
       color="red",
    linestyle="-")
    plt.xlabel("Фактическое значение")
    plt.ylabel("Предсказанное значение")
    plt.title(f"Фактическое vs предсказанное ")
    plt.show()

from sklearn.ensemble import GradientBoostingRegressor  # 1. Gradient Boosting

gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
gb_model.fit(X_train_scaled, y_train)
y_pred_gb = gb_model.predict(X_test_scaled)

mae_gb = mean_absolute_error(y_test, y_pred_gb)
mse_gb = mean_squared_error(y_test, y_pred_gb)
r2_gb = r2_score(y_test, y_pred_gb)
print(f"GBoost - MAE: {mae_gb:.2f}, MSE: {mse_gb:.2f}, R²: {r2_gb:.2f}")

result_visual(y_test,y_pred_gb)

import xgboost as xgb # 2. Экстремальный градиентный бустинг

xgb_model = xgb.XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42)
xgb_model.fit(X_train_scaled, y_train)
y_pred_xgb = xgb_model.predict(X_test_scaled)

mae_xgb = mean_absolute_error(y_test, y_pred_xgb)
mse_xgb = mean_squared_error(y_test, y_pred_xgb)
r2_xgb = r2_score(y_test, y_pred_xgb)
print(f"XGBoost - MAE: {mae_xgb:.2f}, MSE: {mse_xgb:.2f}, R²: {r2_xgb:.2f}")

result_visual(y_test,y_pred_xgb)

from sklearn.tree import DecisionTreeRegressor  # 3. Регрессор дерева решений

dtr_model = DecisionTreeRegressor(max_depth=5, random_state=42)
dtr_model.fit(X_train_scaled, y_train)
y_pred_dtr = dtr_model.predict(X_test_scaled)

mae_dtr = mean_absolute_error(y_test, y_pred_dtr)
mse_dtr = mean_squared_error(y_test, y_pred_dtr)
r2_dtr = r2_score(y_test, y_pred_dtr)
print(f"DecisionTree - MAE: {mae_dtr:.2f}, MSE: {mse_dtr:.2f}, R²: {r2_dtr:.2f}")

result_visual(y_test,y_pred_dtr)

from sklearn.ensemble import RandomForestRegressor #4. Регрессор случайного леса

rfr_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
rfr_model.fit(X_train_scaled, y_train)
y_pred_rfr = rfr_model.predict(X_test_scaled)

mae_rfr = mean_absolute_error(y_test, y_pred_rfr)
mse_rfr = mean_squared_error(y_test, y_pred_rfr)
r2_rfr = r2_score(y_test, y_pred_rfr)
print(f"DecisionTree - MAE: {mae_rfr:.2f}, MSE: {mse_rfr:.2f}, R²: {r2_rfr:.2f}")

result_visual(y_test,y_pred_rfr)

!pip install -q catboost

from catboost import CatBoostRegressor #5. Регрессор CatBoost

cat_model = CatBoostRegressor(iterations=500, max_depth=5, learning_rate=0.1, random_state=42, verbose=0)
cat_model.fit(X_train_scaled, y_train)
y_pred_cat = cat_model.predict(X_test_scaled)

mae_cat = mean_absolute_error(y_test, y_pred_cat)
mse_cat = mean_squared_error(y_test, y_pred_cat)
r2_cat = r2_score(y_test, y_pred_cat)
print(f"DecisionTree - MAE: {mae_cat:.2f}, MSE: {mse_cat:.2f}, R²: {r2_cat:.2f}")

result_visual(y_test,y_pred_cat)

models = ["GradientBoost", "XGBoost", "DecisionTree", "RandomForest", "CatBoost"]
r2_scores = [r2_gb, r2_xgb, r2_dtr, r2_rfr, r2_cat]

plt.figure(figsize=(10, 6))
bars = sns.barplot(x=models, y=r2_scores, hue=models, palette="coolwarm", edgecolor="black", linewidth=1.5, legend=False)

# Adding text labels
for bar in bars.patches:
    bars.annotate(f"{bar.get_height():.3f}",
                  (bar.get_x() + bar.get_width() / 2, bar.get_height()),
                   ha="center", va="bottom", fontsize=12, fontweight="bold", color="black")

plt.title("Сравнение производительности моделей (R² Score)", fontsize=14, fontweight="bold")
plt.ylabel("R² Score", fontsize=12)
plt.xticks(fontsize=11, fontweight="bold", rotation=15)
plt.ylim(0, 1)
plt.grid(axis="y", linestyle="--", alpha=0.5)
plt.show()

import warnings
warnings.filterwarnings("ignore")  # Ignore warnings
import numpy as np

rmse_gb = np.sqrt(mse_gb)
rmse_xgb = np.sqrt(mse_xgb)
rmse_dtr = np.sqrt(mse_dtr)
rmse_rfr = np.sqrt(mse_rfr)
rmse_cat = np.sqrt(mse_cat)

# Visualization
models = ["GradientBoost", "XGBoost", "DecisionTree", "RandomForest", "CatBoost"]
mae_scores = [mae_gb, mae_xgb, mae_dtr, mae_rfr, mae_cat]
mse_scores = [mse_gb, mse_xgb, mse_dtr, mse_rfr, mse_cat]
rmse_scores = [rmse_gb, rmse_xgb, rmse_dtr, rmse_rfr, rmse_cat]

fig, axes = plt.subplots(3, 1, figsize=(7, 7))

# MAE Plot
sns.barplot(x=models, y=mae_scores, ax=axes[0], palette="magma", edgecolor="black", linewidth=1.2)
axes[0].set_title("Mean Absolute Error (MAE)", fontsize=13, fontweight="bold")
axes[0].set_ylabel("MAE ($)", fontsize=11)
axes[0].grid(axis="y", linestyle="--", alpha=0.5)

# MSE Plot
sns.barplot(x=models, y=mse_scores, ax=axes[1], palette="viridis", edgecolor="black", linewidth=1.2)
axes[1].set_title("Mean Squared Error (MSE)", fontsize=13, fontweight="bold")
axes[1].set_ylabel("MSE ($²)", fontsize=11)
axes[1].grid(axis="y", linestyle="--", alpha=0.5)

# RMSE Plot
sns.barplot(x=models, y=rmse_scores, ax=axes[2], palette="coolwarm", edgecolor="black", linewidth=1.2)
axes[2].set_title("Root Mean Squared Error (RMSE)", fontsize=13, fontweight="bold")
axes[2].set_ylabel("RMSE ($)", fontsize=11)
axes[2].grid(axis="y", linestyle="--", alpha=0.5)

plt.tight_layout()
plt.show()

# Summary Table
summary_df = pd.DataFrame({
    "Model": models,
    "R² Score": [r2_gb, r2_xgb, r2_dtr, r2_rfr, r2_cat],
    "MAE": mae_scores,
    "MSE": mse_scores,
    "RMSE": rmse_scores
})

summary_df = summary_df.sort_values(by="R² Score", ascending=False)
print("Сравнение моделей (по R² Score):\n")
print(summary_df.to_string(index=False))

# Print the best model
best_model = summary_df.iloc[0]["Model"]
print(f"\nЛучшая модель: {best_model} с R² Score равным {summary_df.iloc[0]['R² Score']:.3f}")